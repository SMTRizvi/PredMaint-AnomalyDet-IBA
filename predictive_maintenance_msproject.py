# -*- coding: utf-8 -*-
"""predictive_maintenance_MSProject

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wliI3KDNfkKY1Pq0pMPs1sNKg5ZA4ShG
"""

import pandas as pd
import numpy as np

df = pd.read_csv("/content/predictive_maintenance_dataset.csv")
df.head()

df.shape
df['date'] = pd.to_datetime(df['date'])

def extra_features(data):
    # datetime features
    df = data.copy()
    df['day']       = df['date'].dt.day
    df['month']     = df['date'].dt.month
    df['year']      = df['date'].dt.year
    df['day_week']  = df['date'].dt.weekday
    df['weekmonth'] = (df['day'] - 1) // 7 + 1

    # devices features
    df['sector']     = df['device'].str[:4]
    df['equipment']  = df['device'].str[4:]
    return df

df = extra_features(df)
df.nunique()

"""### copied"""

def multi(x,i):
    if x%i == 0:
        return True
    else:
        return False

a = df['metric1'].apply(lambda x: multi(x,8))
a[a == False].count()

import math
df['mnw1'] = df['metric1']/8
df['mnw1'] = df['mnw1'].apply(lambda x: math.ceil(x))

df['metric2'].sort_values().unique()

df[df['metric2'] == 55].metric2.count()
idx = df['metric2'] == 55
df.loc[idx,'metric2'] = 56
df['mnw2'] = df['metric2']/8
df['mnw2'] = df['mnw2'].astype(int)

df['metric3'].sort_values().unique()

df['metric4'].sort_values().unique()

df['metric5'].sort_values().unique()

df['metric6'].sort_values().head(9000).unique()

df['metric7'].sort_values().unique()
df['mnw7'] = df['metric7']/2
df['mnw7'] = df['mnw7'].astype(int)

df['metric8'].sort_values().unique()
df['mnw8'] = df['metric8']/2
df['mnw8'] = df['mnw8'].astype(int)

df['metric9'].sort_values().unique()

df.drop(['metric1','metric2','metric7','metric8'], axis = 1 , inplace = True)

import matplotlib.pyplot as plt
import seaborn as sns

metrics = ['mnw1','mnw2','metric3', 'metric4', 'metric5', 'metric6', 'mnw7', 'mnw8','metric9']
figs, axs = plt.subplots(nrows = len(metrics),ncols = 2,figsize=(15,30))
for i in range(0,len(metrics)):
    sns.histplot(data = df, x = metrics[i], bins = 30, ax = axs[i,0])
    sns.boxplot(data = df, y = metrics[i], ax = axs[i,1])

df['dif_m6'] = df['metric6']
df['dif_m5'] = df['metric5']

df['log_m2'] = np.log(df['mnw2']+1)
df['log_m3'] = np.log(df['metric3']+1)
df['log_m4'] = np.log(df['metric4']+1)
df['log_m7'] = np.log(df['mnw7']+1)
df['log_m8'] = np.log(df['mnw8']+1)
df['log_m9'] = np.log(df['metric9']+1)

df.drop(['mnw2','metric3','metric4','mnw7','mnw8','metric9'], axis = 1, inplace = True)
dev_name = df['device'].unique()

for i in dev_name:
    filt = df[df['device'] == i]
    df.loc[filt.index,'dif_m6'] = filt['dif_m6'] - filt['metric6'].min()
    df.loc[filt.index,'dif_m5'] = filt['dif_m5'] - filt['metric5'].min()

df_cod = df.drop(['failure','equipment','device','date','year'],axis =1)

fig, axes = plt.subplots(1, figsize=(25,25))
kendall_matrix = np.round(df_cod.corr(method='spearman'),2)
fig = sns.heatmap(kendall_matrix, annot=True,linewidths=.1)

df_final = df.drop(['device','log_m8','weekmonth','year','equipment','date','month'],axis =1)
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

X = df_final.drop(['failure'], axis = 1)
y = df_final['failure']
X_train, X_test, Y_train, Y_test = train_test_split(X,y,random_state = 0, test_size=0.25, shuffle = True)
X_train.reset_index(inplace = True, drop = True)
Y_train.reset_index(inplace = True, drop = True)

X_test.reset_index(inplace = True, drop = True)
Y_test.reset_index(inplace = True, drop = True)

def preprocess(X,Y,OHE,low_card,scaler,i,sm):
    x = X.copy()
    y = Y.copy()

    x.reset_index(inplace = True, drop = True)
    y.reset_index(inplace = True, drop = True)

    if i == 1:
        #dealing with low cardinality
        coding_hot = OHE.fit_transform(x[low_card].to_numpy())
        aux = pd.DataFrame(coding_hot, columns = OHE.get_feature_names_out(low_card))
        x = pd.concat([x, aux], axis=1).drop(low_card, axis=1)

        aux = scaler.fit_transform(x)
        x = pd.DataFrame(aux,index=x.index, columns=x.columns)
        xf, yf = sm.fit_resample(x, y)

    else:

        coding_hot = OHE.transform(x[low_card].to_numpy())
        aux = pd.DataFrame(coding_hot, columns = OHE.get_feature_names_out(low_card))
        x = pd.concat([x, aux], axis=1).drop(low_card, axis=1)

        aux2 = scaler.transform(x)
        xf = pd.DataFrame(aux2,index=x.index, columns=x.columns)
        yf = y

    return xf, yf

from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.preprocessing import StandardScaler, MinMaxScaler

x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, random_state = 0, test_size=0.25)

low_card =['sector']

OHE =  OneHotEncoder(handle_unknown = 'ignore',sparse=False)

scaler = StandardScaler()
#scaler = MinMaxScaler()

sm = SMOTE(random_state=0)

X_res, Y_res = preprocess(x_train, y_train,OHE,low_card,scaler,1,sm)
X_val, Y_val = preprocess(x_val, y_val,OHE,low_card,scaler,0,sm)

X_res.head()

Y_res.value_counts()

X_res.shape

X = np.expand_dims(X_res, axis=1)
X.shape

X_val = np.expand_dims(X_val, axis=1)


X_val = X_val.reshape(X_val.shape[0], X_val.shape[2], X_val.shape[1])

X_val.shape

X = X.reshape(X.shape[0], X.shape[2], X.shape[1])
X.shape

import tensorflow as tf
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Dense
from tensorflow.keras import Input
from tensorflow.keras.models import Sequential

model = Sequential()
model.add(Input(shape=(19,1)))
model.add(LSTM(132, return_sequences=False, return_state=False))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
# model.output_shape

model.summary()

model.compile(optimizer="Adam", loss=tf.keras.losses.BinaryCrossentropy(), metrics = [tf.keras.metrics.AUC(), 'accuracy'])

model.fit(X, Y_res, epochs= 3, batch_size = 64)

from sklearn.metrics import recall_score, f1_score, roc_auc_score, confusion_matrix,classification_report



y_pred = model.predict(X_val)

ypred = np.where(y_pred >= 0.00005, 1, 0)

cf_matrix = confusion_matrix(Y_val, ypred)
s = sns.heatmap(cf_matrix, annot=True).set(xlabel='Predicted label', ylabel='True label')

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score

fpr, tpr, thresholds = roc_curve(Y_val, y_pred)

auc = roc_auc_score(Y_val, y_pred)

plt.plot(fpr, tpr, label='ROC curve (AUC = %0.2f)' % auc)
plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc='lower right')
plt.show()

cf_matrix = confusion_matrix(Y_val, ypred)

ypred = np.where(y_pred >= 0.5, 1, 0)

report=classification_report(Y_val,ypred)
print('ROC AUC: ',round(roc_auc_score(Y_val,y_pred),4))
print(report)

import pickle
# Save the model to a file
with open('model.pkl', 'wb') as file:
    pickle.dump(model, file)

# Load the model from the file
with open('model.pkl', 'rb') as file:
    model = pickle.load(file)

pred = model.predict(X_val)

X_val.shape

fpr, tpr, thresholds = roc_curve(Y_val, y_pred)

#model.save('model_lstm.h5')

#model.save("/content/drive/MyDrive/Colab Notebooks/trained_model/model_lstm.h5")